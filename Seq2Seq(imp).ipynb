{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b20a5213-3e27-4a14-b0bf-703aa3d6c41d",
   "metadata": {},
   "source": [
    "## Seq2Seq mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "db9c6298-d4a4-4cb3-b5be-739c6dd217fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3742d4bd-67c9-46ad-b3f7-59b22fd9ceec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ff95c8e-175f-4c6d-939c-7a6cb75f2b98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>gloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How are you today?</td>\n",
       "      <td>TODAY, HOW ARE YOU?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What's your favorite food?</td>\n",
       "      <td>FAVORITE FOOD, WHAT?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Where did you go on vacation?</td>\n",
       "      <td>VACATION WHERE, YOU GO?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Did you watch the game last night?</td>\n",
       "      <td>GAME LAST NIGHT, YOU WATCH?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How's work going?</td>\n",
       "      <td>WORK, HOW GO?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                text                        gloss\n",
       "0           0                  How are you today?          TODAY, HOW ARE YOU?\n",
       "1           1          What's your favorite food?         FAVORITE FOOD, WHAT?\n",
       "2           2       Where did you go on vacation?      VACATION WHERE, YOU GO?\n",
       "3           3  Did you watch the game last night?  GAME LAST NIGHT, YOU WATCH?\n",
       "4           4                   How's work going?                WORK, HOW GO?"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e2d48be-01c4-4fa1-b8d9-4a252ef62014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Unnamed: 0    0\n",
       "text          0\n",
       "gloss         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37795009-7b36-49a3-a372-e28e3395ca1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>gloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>225.000000</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>225</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>How are you today?</td>\n",
       "      <td>TODAY, HOW ARE YOU?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>73.111111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>52.138304</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>62.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>118.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>174.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Unnamed: 0                text                gloss\n",
       "count   225.000000                 225                  225\n",
       "unique         NaN                 225                  225\n",
       "top            NaN  How are you today?  TODAY, HOW ARE YOU?\n",
       "freq           NaN                   1                    1\n",
       "mean     73.111111                 NaN                  NaN\n",
       "std      52.138304                 NaN                  NaN\n",
       "min       0.000000                 NaN                  NaN\n",
       "25%      28.000000                 NaN                  NaN\n",
       "50%      62.000000                 NaN                  NaN\n",
       "75%     118.000000                 NaN                  NaN\n",
       "max     174.000000                 NaN                  NaN"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f5d50bf-19dc-45af-b2c3-a0f9e04fb618",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(225, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "332d3b41-3e41-4f43-99f1-115a111f416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_n(inp):\n",
    "    return inp.replace(\"\\n\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12c96e18-30d9-4e9d-82d5-ac22b8bce974",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"gloss\"]=df[\"gloss\"].apply(remove_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "efe5d294-7db8-4e05-bbbc-67bf177eb6fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>gloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How are you today?</td>\n",
       "      <td>TODAY, HOW ARE YOU?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What's your favorite food?</td>\n",
       "      <td>FAVORITE FOOD, WHAT?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Where did you go on vacation?</td>\n",
       "      <td>VACATION WHERE, YOU GO?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Did you watch the game last night?</td>\n",
       "      <td>GAME LAST NIGHT, YOU WATCH?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How's work going?</td>\n",
       "      <td>WORK, HOW GO?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                text                        gloss\n",
       "0           0                  How are you today?          TODAY, HOW ARE YOU?\n",
       "1           1          What's your favorite food?         FAVORITE FOOD, WHAT?\n",
       "2           2       Where did you go on vacation?      VACATION WHERE, YOU GO?\n",
       "3           3  Did you watch the game last night?  GAME LAST NIGHT, YOU WATCH?\n",
       "4           4                   How's work going?                WORK, HOW GO?"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "08714756-8a6a-41f8-84e1-fa477028fae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"]=df[\"text\"].apply(remove_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92cca98f-b642-44c0-84de-a459f16c0b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>gloss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>How are you today?</td>\n",
       "      <td>TODAY, HOW ARE YOU?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What's your favorite food?</td>\n",
       "      <td>FAVORITE FOOD, WHAT?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Where did you go on vacation?</td>\n",
       "      <td>VACATION WHERE, YOU GO?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Did you watch the game last night?</td>\n",
       "      <td>GAME LAST NIGHT, YOU WATCH?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>How's work going?</td>\n",
       "      <td>WORK, HOW GO?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                text                        gloss\n",
       "0           0                  How are you today?          TODAY, HOW ARE YOU?\n",
       "1           1          What's your favorite food?         FAVORITE FOOD, WHAT?\n",
       "2           2       Where did you go on vacation?      VACATION WHERE, YOU GO?\n",
       "3           3  Did you watch the game last night?  GAME LAST NIGHT, YOU WATCH?\n",
       "4           4                   How's work going?                WORK, HOW GO?"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1c781c7-d87d-4869-9b20-0f44d943396f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51d0637c-c496-4d7c-a6d8-08b675db57bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_texts=df[\"text\"].values\n",
    "gloss_texts=df[\"gloss\"].values\n",
    "text_texts = ['<start> ' + sentence + ' <end>' for sentence in text_texts]\n",
    "gloss_texts = ['<start>' + sentence + ' <end>' for sentence in gloss_texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4e39963e-d945-4063-8be4-4d4fd85693f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_tokenizer = Tokenizer()\n",
    "text_tokenizer.fit_on_texts(text_texts)\n",
    "text_vocab_size = len(text_tokenizer.word_index) + 1\n",
    "text_sequences = text_tokenizer.texts_to_sequences(text_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d53373d-c967-412b-8758-cd3393785444",
   "metadata": {},
   "outputs": [],
   "source": [
    "gloss_tokenizer = Tokenizer()\n",
    "gloss_tokenizer.fit_on_texts(gloss_texts)\n",
    "gloss_vocab_size = len(gloss_tokenizer.word_index) + 1\n",
    "gloss_sequences = gloss_tokenizer.texts_to_sequences(gloss_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c1f1c8c-fde3-42c3-94a2-1ebc68daba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_text_seq_length = max([len(seq) for seq in text_sequences])\n",
    "max_gloss_seq_length = max([len(seq) for seq in gloss_sequences])\n",
    "\n",
    "text_sequences = pad_sequences(text_sequences, maxlen=max_text_seq_length, padding='post')\n",
    "gloss_sequences = pad_sequences(gloss_sequences, maxlen=max_gloss_seq_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a5ce6768-3cc0-4c13-a837-014233763dfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and validation sets\n",
    "encoder_input_data, encoder_input_data_val, decoder_input_data, decoder_input_data_val = train_test_split(\n",
    "    text_sequences, gloss_sequences, test_size=0.2)\n",
    "\n",
    "# Create decoder target data\n",
    "decoder_target_data = np.zeros_like(decoder_input_data)\n",
    "decoder_target_data[:, :-1] = decoder_input_data[:, 1:]\n",
    "#decoder_target_data[:, -1] = gloss_tokenizer.word_index['<end>']  # Ensure you have an end token\n",
    "\n",
    "decoder_target_data_val = np.zeros_like(decoder_input_data_val)\n",
    "decoder_target_data_val[:, :-1] = decoder_input_data_val[:, 1:]\n",
    "#decoder_target_data_val[:, -1] = gloss_tokenizer.word_index['<end>']  # Ensure you have an end token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "710d5fe9-1524-4477-bde4-de4bb91f7227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\devis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\devis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\devis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "3/3 [==============================] - 15s 2s/step - loss: 6.4985 - val_loss: 6.4828\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x1d79cd326d0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
    "\n",
    "# Define the dimensions\n",
    "latent_dim = 256\n",
    "\n",
    "# Define the encoder\n",
    "encoder_inputs = Input(shape=(None,))\n",
    "encoder_embedding = Embedding(text_vocab_size, latent_dim, mask_zero=True)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_embedding)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Define the decoder\n",
    "decoder_inputs = Input(shape=(None,))\n",
    "decoder_embedding = Embedding(gloss_vocab_size, latent_dim, mask_zero=True)(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "decoder_dense = Dense(gloss_vocab_size, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "# Define the Seq2Seq model\n",
    "model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n",
    "\n",
    "# Train the model\n",
    "model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=64, epochs=1, validation_data=([encoder_input_data_val, decoder_input_data_val], decoder_target_data_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c03966e1-cee5-4add-a201-0c5ff2d54894",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"lstm_4\" (type LSTM).\n\nDimensions must be equal, but are 1024 and 256 for '{{node mul}} = Mul[T=DT_FLOAT](Sigmoid_1, init_c)' with input shapes: [?,?,1024], [?,256].\n\nCall arguments received by layer \"lstm_4\" (type LSTM):\n  • inputs=['tf.Tensor(shape=(None, None, 1, 256), dtype=float32)', 'tf.Tensor(shape=(None, 256), dtype=float32)', 'tf.Tensor(shape=(None, 256), dtype=float32)']\n  • mask=['tf.Tensor(shape=(None, None, 1), dtype=bool)', 'None', 'None']\n  • training=None\n  • initial_state=None",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 33\u001b[0m\n\u001b[0;32m     30\u001b[0m decoder_states_inputs \u001b[38;5;241m=\u001b[39m [decoder_state_input_h, decoder_state_input_c]\n\u001b[0;32m     32\u001b[0m decoder_embedding_inf \u001b[38;5;241m=\u001b[39m Embedding(gloss_vocab_size, latent_dim, mask_zero\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(decoder_inputs)\n\u001b[1;32m---> 33\u001b[0m decoder_outputs, state_h, state_c \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_lstm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     34\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_embedding_inf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_states_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m decoder_states \u001b[38;5;241m=\u001b[39m [state_h, state_c]\n\u001b[0;32m     36\u001b[0m decoder_outputs \u001b[38;5;241m=\u001b[39m decoder_dense(decoder_outputs)\n",
      "File \u001b[1;32mc:\\Users\\devis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\base_rnn.py:615\u001b[0m, in \u001b[0;36mRNN.__call__\u001b[1;34m(self, inputs, initial_state, constants, **kwargs)\u001b[0m\n\u001b[0;32m    613\u001b[0m \u001b[38;5;66;03m# Perform the call with temporarily replaced input_spec\u001b[39;00m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec \u001b[38;5;241m=\u001b[39m full_input_spec\n\u001b[1;32m--> 615\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfull_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    616\u001b[0m \u001b[38;5;66;03m# Remove the additional_specs from input spec and keep the rest. It\u001b[39;00m\n\u001b[0;32m    617\u001b[0m \u001b[38;5;66;03m# is important to keep since the input spec was populated by\u001b[39;00m\n\u001b[0;32m    618\u001b[0m \u001b[38;5;66;03m# build(), and will be reused in the stateful=True.\u001b[39;00m\n\u001b[0;32m    619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_spec[: \u001b[38;5;241m-\u001b[39m\u001b[38;5;28mlen\u001b[39m(additional_specs)]\n",
      "File \u001b[1;32mc:\\Users\\devis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\devis\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\rnn\\lstm.py:975\u001b[0m, in \u001b[0;36mstandard_lstm.<locals>.step\u001b[1;34m(cell_inputs, cell_states)\u001b[0m\n\u001b[0;32m    973\u001b[0m i \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msigmoid(z0)\n\u001b[0;32m    974\u001b[0m f \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msigmoid(z1)\n\u001b[1;32m--> 975\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mc_tm1\u001b[49m \u001b[38;5;241m+\u001b[39m i \u001b[38;5;241m*\u001b[39m tf\u001b[38;5;241m.\u001b[39mtanh(z2)\n\u001b[0;32m    976\u001b[0m o \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39msigmoid(z3)\n\u001b[0;32m    978\u001b[0m h \u001b[38;5;241m=\u001b[39m o \u001b[38;5;241m*\u001b[39m tf\u001b[38;5;241m.\u001b[39mtanh(c)\n",
      "\u001b[1;31mValueError\u001b[0m: Exception encountered when calling layer \"lstm_4\" (type LSTM).\n\nDimensions must be equal, but are 1024 and 256 for '{{node mul}} = Mul[T=DT_FLOAT](Sigmoid_1, init_c)' with input shapes: [?,?,1024], [?,256].\n\nCall arguments received by layer \"lstm_4\" (type LSTM):\n  • inputs=['tf.Tensor(shape=(None, None, 1, 256), dtype=float32)', 'tf.Tensor(shape=(None, 256), dtype=float32)', 'tf.Tensor(shape=(None, 256), dtype=float32)']\n  • mask=['tf.Tensor(shape=(None, None, 1), dtype=bool)', 'None', 'None']\n  • training=None\n  • initial_state=None"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Embedding\n",
    "\n",
    "# Assuming these variables are defined elsewhere in your script\n",
    "latent_dim = 256\n",
    "gloss_vocab_size = 5000  # Example size, replace with your actual vocab size\n",
    "\n",
    "# Define the encoder inputs with the correct shape (timesteps, features)\n",
    "encoder_inputs = Input(shape=(None, 1))  # Adjust feature dimension as necessary\n",
    "\n",
    "# Define the encoder LSTM\n",
    "encoder_lstm = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder_lstm(encoder_inputs)\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Encoder model for inference\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Define the decoder inputs with the correct shape\n",
    "decoder_inputs = Input(shape=(None, 1))  # Adjust feature dimension as necessary\n",
    "\n",
    "# Define the decoder LSTM\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_dense = Dense(gloss_vocab_size, activation='softmax')\n",
    "\n",
    "# Decoder model for inference\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_embedding_inf = Embedding(gloss_vocab_size, latent_dim, mask_zero=True)(decoder_inputs)\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_embedding_inf, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse word index for decoding\n",
    "reverse_text_word_index = {i: word for word, i in text_tokenizer.word_index.items()}\n",
    "reverse_gloss_word_index = {i: word for word, i in gloss_tokenizer.word_index.items()}\n",
    "\n",
    "max_seq_length = 400\n",
    "\n",
    "# Function to decode the sequence\n",
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "    \n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1))\n",
    "    # Populate the first token of target sequence with the start token.\n",
    "    # target_seq[0, 0] = gloss_tokenizer.word_index['<start>']\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(\n",
    "            [target_seq] + states_value)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_gloss_word_index.get(sampled_token_index, '')\n",
    "        decoded_sentence += ' ' + sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length or find stop character.\n",
    "        if (sampled_char == '<end>' or len(decoded_sentence) > max_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1))\n",
    "        target_seq[0, 0] = sampled_token_index\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence.strip()\n",
    "\n",
    "# Example of using the inference function\n",
    "input_seq = encoder_input_data[1:2]  # Taking the first sequence for translation\n",
    "translation = decode_sequence(input_seq)\n",
    "print('Encoded:', translation)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
